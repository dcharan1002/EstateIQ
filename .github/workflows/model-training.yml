name: Model Training Pipeline

on:
  push:
    branches: [ main ]
    paths:
      - 'src/model/**'
      - 'Data/final/**'
  workflow_dispatch:

env:
  PROJECT_ID: estateiqclone
  REGION: us-central1
  ARTIFACT_REGISTRY: estateiq-models
  MODEL_PATH: models/estate_price_prediction
  SA_EMAIL: self-522@estateiqclone.iam.gserviceaccount.com
  GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
  NOTIFICATION_EMAIL: ${{ secrets.NOTIFICATION_EMAIL }}
  MLFLOW_TRACKING_URI: sqlite:///mlflow.db

jobs:
  train-model:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install dvc[gs] google-cloud-storage

    - name: Google Auth
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}
        service_account: ${{ env.SA_EMAIL }}

    - name: Set up Cloud SDK
      uses: google-github-actions/setup-gcloud@v2

    - name: Setup DVC and Pull Data
      run: |
        echo '${{ secrets.GCP_SA_KEY }}' > key.json
        
        # Configure DVC remotes
        dvc remote modify myremote credentialpath key.json
        dvc remote modify data credentialpath key.json
        
        # Debug - List remotes
        echo "DVC Remotes:"
        dvc remote list
        
        # Pull data
        dvc pull || echo "Warning: DVC pull had issues"
        
        # Create Data directory if it doesn't exist
        mkdir -p Data
        
        # Create symbolic link from data to Data
        if [ -d "data" ]; then
          echo "Creating symbolic links from data/ to Data/"
          for dir in data/*; do
            if [ -d "$dir" ]; then
              base=$(basename "$dir")
              mkdir -p "Data/$base"
              cp -r "$dir"/* "Data/$base/"
            fi
          done
        else
          echo "Warning: data directory not found after DVC pull"
        fi
        
        # Debug - List directories
        echo "Directory structure after setup:"
        ls -la
        echo "Data directory contents:"
        ls -la Data/ || echo "No Data directory"
        echo "data directory contents:"
        ls -la data/ || echo "No data directory"

    - name: Train Model (Cloud Build)
      run: |
        gcloud builds submit . \
          --config=cloudbuild.yaml \
          --project=${{ env.PROJECT_ID }} \
          --substitutions=_PROJECT_ID=${{ env.PROJECT_ID }},_ARTIFACT_REGISTRY=${{ env.ARTIFACT_REGISTRY }},_MODEL_PATH=${{ env.MODEL_PATH }},_REGION=${{ env.REGION }},_MLFLOW_TRACKING_URI=${{ env.MLFLOW_TRACKING_URI }},_GMAIL_APP_PASSWORD="${{ env.GMAIL_APP_PASSWORD }}",_NOTIFICATION_EMAIL="${{ env.NOTIFICATION_EMAIL }}"

    - name: Verify Training Success
      id: verify_training
      run: |
        # Wait for metrics file
        for i in {1..10}; do
          if gcloud storage ls gs://${{ env.ARTIFACT_REGISTRY }}/${{ env.MODEL_PATH }}/current/metrics.json; then
            echo "Metrics file found"
            break
          fi
          if [ $i -eq 10 ]; then
            echo "Timeout waiting for metrics file"
            exit 1
          fi
          sleep 30
        done

        # Check metrics
        gcloud storage cp gs://${{ env.ARTIFACT_REGISTRY }}/${{ env.MODEL_PATH }}/current/metrics.json ./metrics.json
        if jq -e '.metrics.r2' metrics.json > /dev/null; then
          echo "::set-output name=training_success::true"
        else
          echo "::set-output name=training_success::false"
          exit 1
        fi

    - name: Notify on Failure
      if: failure()
      run: |
        echo "Model training pipeline failed. Please check the logs for details."
        exit 1
